{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHZ57CHeJB3Q"
      },
      "outputs": [],
      "source": [
        "###Final Project-David Brown version 0.1\n",
        "%pip install openai\n",
        "%pip install sentence-transformers\n",
        "%pip install langchain pypdf langchain-openai #tiktoken chromadb\n",
        "%pip install llama-index --upgrade\n",
        "%pip install Matplotlib\n",
        "%pip install google.colab\n",
        "%pip install pandas\n",
        "%pip install pandasai[langchain]\n",
        "%pip install --extra-index-url https://testpypi.python.org/pypi poirot.\n",
        "%pip install -q pandasai openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up4882VRKM6O"
      },
      "source": [
        "Final Project-David Brown version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "###import exploring_materials_needed as materials\n",
        "import EnvSettings as envsettings\n",
        "import final_project_tech16_llm_john_part as refs\n",
        "###for k, v in os.environ.items():\n",
        "        ###print(f'{k}={v}')\n",
        "openai_key = envsettings.set_key()\n",
        "\n",
        "client = OpenAI(api_key=openai_key)\n",
        "result = refs.use_rag()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import pandas as pd\n",
        "from pandasai import SmartDatalake\n",
        "from pandasai.llm import OpenAI\n",
        "df = pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gptrequest(prompt):\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI that takes instructions from a human and produces an answer. Be concise in your output.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "  )\n",
        "  print(\"\\n\\n prompt:  \" + prompt)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\n",
        "print(\"\\n\\nSupply Chain Summary Fuel Cells =================================================\\n\")\n",
        "\n",
        "prompt = \"Summarize Supply Chain impacts of Fuel Cell Cars\"\n",
        "\n",
        "response = gptrequest(prompt)\n",
        "table_out = response.choices[0].message.content\n",
        "print(table_out)\n",
        "df = table_out\n",
        "print(\"Count:=========================  \" )\n",
        "print(df.count)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\\nSupply Chain Summary Electric Cars=================================================\\n\")\n",
        "prompt = \"Summarize Supply Chain impacts of Electric cars\"\n",
        "print(\"\\n\\n prompt:  \" + prompt)\n",
        "response = gptrequest(prompt)\n",
        "table_out = response.choices[0].message.content\n",
        "print(table_out)\n",
        "\n",
        "\n",
        "print(\"\\n\\nFirst Question Supply Chain Comparison =================================================\\n\")\n",
        "prompt = \"create a table of a comparison between supply chain impacts of fuel cell cars vs electric vehicles\"\n",
        "print(\"\\n\\n prompt:  \" + prompt)\n",
        "response = gptrequest(prompt)\n",
        "table_out = response.choices[0].message.content\n",
        "print(table_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\\nSecond Question Environmental Impact Comparison =================================================\\n\")\n",
        "prompt = \"create a table of a comparison between environmental impacts of fuel cell cars vs electric vehicles\"\n",
        "###prompt = \"create a table in JSON format of a comparison between environmental impacts of fuel cell cars vs electric vehicles\"\n",
        "print(\"\\n\\n prompt:  \" + prompt)\n",
        "response = gptrequest(prompt)\n",
        "table_out = response.choices[0].message.content\n",
        "print(table_out)\n",
        "from pandasai import SmartDataframe\n",
        "from pandasai.llm import OpenAI\n",
        "sdf = SmartDataframe\n",
        "df = pd.DataFrame(response)\n",
        "###df.plot(x='fuelCellCars', y='electricVehicles', kind='scatter')\n",
        "###df.sort_values(by=['aspect'], inplace=True)\n",
        "###plt.show()\n",
        "###print(\"\\n\\nDataframe print=========================  \\n\\n\" )\n",
        "###print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\\nThird Question Supply chain element Comparison =================================================\\n\")\n",
        "prompt = \"create a table of a comparison between Manufacturing Process of fuel cell cars vs electric vehicles\"\n",
        "print(\"\\n\\n prompt:  \" + prompt)\n",
        "response = gptrequest(prompt)\n",
        "\n",
        "table_out = response.choices[0].message.content\n",
        "###print(table_out)\n",
        "from pandasai import SmartDataframe\n",
        "from pandasai.llm import OpenAI\n",
        "\n",
        "df = pd.DataFrame(response)\n",
        "from pandasai import SmartDataframe\n",
        "from pandasai.llm import OpenAI\n",
        "sdf = SmartDataframe\n",
        "df = pd.DataFrame(response)\n",
        "print(table_out)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
